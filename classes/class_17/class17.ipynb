{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class : Count-based data 1: coverage and variant calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Before Class\n",
    "1. Install bowtie2, samtools, and bamnostic: `conda install bowtie2 samtools bamnostic`\n",
    "* Review bowtie2, samtools, and bamnostic documentation\n",
    "* Review Counter from collections\n",
    "---\n",
    "## Learning Objectives\n",
    "\n",
    "1. Use BWT algorithm to map reads to a genome\n",
    "* Implement 'pileup' method\n",
    "* Call variants from DNA sequencing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before class:\n",
    "`conda install bowtie2 bamnostic samtools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bamnostic\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/54/c0794de92e8690ee0c09023f6be4dcc1aeb583dc34ffb488c98f78a1449c/bamnostic-1.0.8.tar.gz (185kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 11.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: bamnostic\n",
      "  Running setup.py bdist_wheel for bamnostic ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/loganaw/.cache/pip/wheels/e1/73/a6/043a49dbc82674cc1864eaa28fddbbe35c7f850b163c65ffdc\n",
      "Successfully built bamnostic\n",
      "Installing collected packages: bamnostic\n",
      "Successfully installed bamnostic-1.0.8\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/loganaw/miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - bowtie2\n",
      "    - bwa\n",
      "    - samtools\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bowtie2-2.3.4.3            |   py37he860b03_1        11.9 MB  bioconda\n",
      "    bwa-0.7.17                 |       h84994c4_5         501 KB  bioconda\n",
      "    bzip2-1.0.6                |       h14c3975_5         414 KB\n",
      "    curl-7.64.0                |       hbc83047_2         152 KB\n",
      "    krb5-1.16.1                |       h173b8e3_7         1.4 MB\n",
      "    libcurl-7.64.0             |       h20c2e04_2         600 KB\n",
      "    libdeflate-1.0             |       h14c3975_1          43 KB  bioconda\n",
      "    libssh2-1.8.0              |       h1ba5d50_4         233 KB\n",
      "    perl-5.26.2                |       h14c3975_0        15.9 MB\n",
      "    samtools-1.9               |      h8571acd_11         636 KB  bioconda\n",
      "    tbb-2019.4                 |       hfd86e86_0         1.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        33.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bowtie2            bioconda/linux-64::bowtie2-2.3.4.3-py37he860b03_1\n",
      "  bwa                bioconda/linux-64::bwa-0.7.17-h84994c4_5\n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.6-h14c3975_5\n",
      "  curl               pkgs/main/linux-64::curl-7.64.0-hbc83047_2\n",
      "  krb5               pkgs/main/linux-64::krb5-1.16.1-h173b8e3_7\n",
      "  libcurl            pkgs/main/linux-64::libcurl-7.64.0-h20c2e04_2\n",
      "  libdeflate         bioconda/linux-64::libdeflate-1.0-h14c3975_1\n",
      "  libssh2            pkgs/main/linux-64::libssh2-1.8.0-h1ba5d50_4\n",
      "  perl               pkgs/main/linux-64::perl-5.26.2-h14c3975_0\n",
      "  samtools           bioconda/linux-64::samtools-1.9-h8571acd_11\n",
      "  tbb                pkgs/main/linux-64::tbb-2019.4-hfd86e86_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!pip install bamnostic\n",
    "!conda install -c bioconda bwa samtools bowtie2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bamnostic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5437cb7c0103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbamnostic\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinom_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bamnostic'"
     ]
    }
   ],
   "source": [
    "import bamnostic as bs\n",
    "from collections import Counter\n",
    "from scipy.stats import binom_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mapping to a genome\n",
    "\n",
    "In our previous class, we developed our own tool for mapping reads to a genome using the efficient BWT algorithm. Today, we will be using an existing implementation of this algorithm to align many reads to a small genome. \n",
    "\n",
    "For the next few classes, we will be working with a small genome that we will assume represents a sample from a diploid individual from a population. The genome itself is quite small at ~9kb and contains only a few genes to make analysis during class tractable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use our original get_fasta function to examine the fasta file for the genome\n",
    "import sys\n",
    "sys.path.insert(0, '../shared/')\n",
    "from data_readers import get_fasta\n",
    "file = \"data/sample_genome.fna\"\n",
    "\n",
    "for name, seq in get_fasta(file):\n",
    "    print(seq[1:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step will be creating an index using BWT so that we can align reads. To accomplish this, we could use the code from class. However, because we only allow for exact matches, we wouldn't be able to identify variants in our data. Instead, we will be using an aligner that uses the same algorithm that we implemented but allows for some mismatches to the genome called Bowtie2 ( http://bowtie-bio.sourceforge.net/bowtie2/index.shtml ). Because this is building the index of the reference genome (the Burrows-Wheeler transform), you only have to do this once for our genome.\n",
    "\n",
    "First, create an index of the reference genome using `bowtie2-build`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the usage information for bowtie2-build\n",
    "! bowtie2-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above, the correct format for building an index is:\n",
    "# bowtie2-build <our genome FASTA file> <name of the index we create>\n",
    "! bowtie2-build data/sample_genome.fna sample_genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created an index, you can map our reads to the genome. We have a set of simulated illumina DNA reads from this genome available in `data/sample_reads.fa`. To accomplish this, use `bowtie2` and write your files to `sample_reads.sam` using the `-S` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the usage information for bowtie2\n",
    "! bowtie2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above, the correct format for building an index is:\n",
    "# bowtie2 -f -x <name of the index we created> -U <FASTA of sequence reads> -S <name of SAM output file>\n",
    "# *We use -f because our input is a fasta file\n",
    "! bowtie2 -f -x sample_genome -U data/sample_reads.fa -S sample_reads.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to convert the sam file into a bam file using samtools sort. You can read more about samtools: http://www.htslib.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the usage information for samtools sort\n",
    "! samtools sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above, the correct format for building the bam file is:\n",
    "# samtools sort -o <name of bam file output> <name of sam file input>\n",
    "! samtools sort -o sample_reads.bam sample_reads.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now mapped your reads to a reference genome using the Burrows-Wheeler algorithm! You can take a look at the sample_reads.sam file to see the plain text version of the alignments and the sample_reads.bam now contains a compressed version of the same alignments.\n",
    "\n",
    "---\n",
    "## Identifying variants in the genome\n",
    "\n",
    "For the second section of today's class, we will be identifying variants in our diploid genome. We will be using the `bamnostic` package ( https://github.com/betteridiot/bamnostic ) to work with our aligned reads from a bam file.\n",
    "\n",
    "To identify variants, we will test each position for non-reference alleles and perform a binomial test to determine if there is indeed a variant or just a sequencing error at that position. This algorithm is somtimes referred to as a 'pileup'.\n",
    "\n",
    "```\n",
    "find_variants(bam_file):\n",
    "    For each position in genome:\n",
    "        count allele frequencies (pileup)\n",
    "        test for heterozygosity\n",
    "        test for homozygous alternative allele\n",
    "```\n",
    "\n",
    "Note: There are multuple ways to implement this, however we recommend using `Counter()` from `collections` that has been discussed and demonstrated multiple times on the office hours live streams. The binomial test can be implemented directly from the equation below, or you can use scipy.stats.\n",
    "\n",
    "Binomial test is calculated as: $P(X=k) = {n \\choose k}p^{k}(1-p)^{n-k}$ where $k$ is the allele count, $n$ is the total number of reads, and $p$ is 0.50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bamnostic as bs\n",
    "from collections import Counter\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "def get_pileup(alignments, region_start = None, region_end = None):\n",
    "    ''' Function build a read pileup list\n",
    "        this is implemented as a list of Counter() from region_start to region_end\n",
    "        with our small genome, it is reasonable to cover the entire genome\n",
    "        but for larger genomes a smaller window is required.\n",
    "    \n",
    "    Args:\n",
    "        alignments (str): bam file of alignments\n",
    "        region_start (int): start position to build pileup\n",
    "        region_end (int): end position to build pileup\n",
    "    \n",
    "    Returns:\n",
    "        genome (list of Counter()): a list from region_start to region_end of\n",
    "            Counters of allele frequencies\n",
    "        \n",
    "    Example:\n",
    "        >>> get_pileup('sample_reads.bam') #doctest: +ELLIPSIS +NORMALIZE_WHITESPACE \n",
    "        [Counter({'G': 5}), Counter({'G': 8}), Counter({'T': 12}), ...] \n",
    "    '''\n",
    "    \n",
    "\n",
    "def binomial_test(major, minor):\n",
    "    ''' Function to perform binomial test\n",
    "        We will consider a Pvalue threshold of 0.10: \n",
    "        SNPs for which the P value of the binomial test < 0.10 failed the heterozygosity test.\n",
    "\n",
    "    Args:\n",
    "        major (int): count of most frequent allele\n",
    "        minor (int): count of second most frequent allele\n",
    "    \n",
    "    Returns:\n",
    "        is_above_threshold (bool): true if passes heterozygosity test, otherwise false\n",
    "        \n",
    "    Example:\n",
    "        >>> binomial_test(8, 4)\n",
    "        True\n",
    "    '''\n",
    "    \n",
    "\n",
    "def find_variants(reference, alignments):\n",
    "    ''' Function to find variants given sequencing alignments and a reference\n",
    "        Identify variants that are heterozygous using heterozygosity test\n",
    "        Identify variants that are homozygous alternative allele\n",
    "        \n",
    "        Note: Variants are reported as 1-based coordinates\n",
    "        \n",
    "    Args:\n",
    "        reference (str): genome reference fasta file\n",
    "        alignments (str): sequence alignments\n",
    "    \n",
    "    Returns:\n",
    "        variant_list (list of tuples): list of variants as (position, allele1, allele2)\n",
    "        \n",
    "    Example:\n",
    "        >>> find_variants(reference = 'data/sample_genome.fna', alignments = 'sample_reads.bam') #doctest: +ELLIPSIS +NORMALIZE_WHITESPACE \n",
    "        [(240, 'A', 'G'), (354, 'G', 'A'), (803, 'C', 'A'), ...]\n",
    "    '''\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_variants(reference = 'data/sample_genome.fna', alignments = 'sample_reads.bam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
