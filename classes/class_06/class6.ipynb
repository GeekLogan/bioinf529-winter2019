{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class : Graphical Models - Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before Class\n",
    "In class today we will be implementing a Markov chain to process sentences\n",
    "Prior to class, please do the following:\n",
    "1. Review slides on Markov chains in detail\n",
    "* Explore using the python dict() structure and how a dict() can contain nested dict() structures\n",
    "* Again, review numpy.random.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "\n",
    "1. Conceptually understand Markov Chains\n",
    "* Implement a Markov Chain\n",
    "* Generate data using Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the lectures that Markov Chains represent a series of events following the Markov Property: future states are memory-less in that they depend only on the current state. This can be expanded to the idea of variable order Markov models where there is a variable-length memory (eg. 1st order Markov Model). Markov models consist of fully observable states. A common example of this is in predicting the weather: We can clearly see the current weather and would like to predict tomorrow's weather. As shown in the slides, this is also applicable to biology with one case being CpG islands. \n",
    "\n",
    "Our goal today will be to implement a Markov model built from words. For our example text, we will use the classic example of Dr. Seuss because of the repetitive nature of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Markov model\n",
    "\n",
    "For our initial implementation of the Markov Model, we will use the simple example of Dr. Seuss: \"One fish two fish red fish blue fish.\" To match my expected output, use a start state of $*S*$ and an end state of $*E*$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_markov_model(markov_model, new_text):\n",
    "    '''\n",
    "    Function to build or add to a 1st order Markov model given a string of text\n",
    "    We will store the markov model as a dictionary of dictionaries\n",
    "    The key in the outer dictionary represents the current state\n",
    "    and the inner dictionary represents the next state with their contents containing\n",
    "    the transition probabilities.\n",
    "    Note: This would be easier to read if we were to build a class representation\n",
    "           of the model rather than a dictionary of dictionaries, but for simplicitiy\n",
    "           our implementation will just use this structure.\n",
    "    \n",
    "    Args: \n",
    "        markov_model (dict of dicts): a dictionary of word:(next_word:frequency pairs)\n",
    "        new_text (str): a string to build or add to the moarkov_model\n",
    "\n",
    "    Returns:\n",
    "        markov_model (dict of dicts): an updated markov_model\n",
    "        \n",
    "    Pseudocode:\n",
    "        Add artificial states for start and end\n",
    "        For each word in text:\n",
    "            Increment markov_model[word][next_word]\n",
    "        \n",
    "    '''\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = dict()\n",
    "text = \"one fish two fish red fish blue fish\"\n",
    "markov_model = build_markov_model(markov_model, text)\n",
    "print (markov_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "{'*S*': {'one': 1}, 'one': {'fish': 1}, 'fish': {'two': 1, 'red': 1, 'blue': 1, '*E*': 1}, 'two': {'fish': 1}, 'red': {'fish': 1}, 'blue': {'fish': 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text from Markov Model\n",
    "\n",
    "Markov models are \"generative models\". That is, the probability states in the model can be used to generate output following the conditional probabilities in the model.\n",
    "\n",
    "We will now generate a sequence of text from the Markov model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(current_word, markov_model):\n",
    "    '''\n",
    "    Function to randomly move a valid next state given a markov model\n",
    "    and a current state (word)\n",
    "    \n",
    "    Args: \n",
    "        current_word (str): a word that exists in our model\n",
    "        markov_model (dict of dicts): a dictionary of word:(next_word:frequency pairs)\n",
    "\n",
    "    Returns:\n",
    "        next_word (str): a randomly selected next word based on transition probabilies\n",
    "        \n",
    "    Pseudocode:\n",
    "        Calculate transition probilities for all next states from a given state (counts/sum)\n",
    "        Randomly draw from these to generate the next state\n",
    "        \n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "def generate_random_text(markov_model):\n",
    "    '''\n",
    "    Function to generate text given a markov model\n",
    "    \n",
    "    Args: \n",
    "        markov_model (dict of dicts): a dictionary of word:(next_word:frequency pairs)\n",
    "\n",
    "    Returns:\n",
    "        sentence (str): a randomly generated sequence given the model\n",
    "        \n",
    "    Pseudocode:\n",
    "        Initialize sentence at start state\n",
    "        Until End State:\n",
    "            append get_next_word(current_word, markov_model)\n",
    "        Return sentence\n",
    "        \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random sentence from our markov chain:\n",
    "print (generate_random_text(markov_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now just add some more training data to the markov model\n",
    "markov_model = build_markov_model(markov_model, \"black fish blue fish old fish new fish\")\n",
    "markov_model = build_markov_model(markov_model, \"this one has a little car\")\n",
    "markov_model = build_markov_model(markov_model, \"this one has a little star\")\n",
    "markov_model = build_markov_model(markov_model, \"say what a lot of fish there are\")\n",
    "markov_model = build_markov_model(markov_model, \"yes some are red and some are blue\")\n",
    "markov_model = build_markov_model(markov_model, \"some are old and some are new\")\n",
    "\n",
    "print(markov_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "{'*S*': {'one': 1, 'black': 1, 'this': 2, 'say': 1, 'yes': 1, 'some': 1}, 'one': {'fish': 1, 'has': 2}, 'fish': {'two': 1, 'red': 1, 'blue': 2, '*E*': 2, 'old': 1, 'new': 1, 'there': 1}, 'two': {'fish': 1}, 'red': {'fish': 1, 'and': 1}, 'blue': {'fish': 2, '*E*': 1}, 'black': {'fish': 1}, 'old': {'fish': 1, 'and': 1}, 'new': {'fish': 1, '*E*': 1}, 'this': {'one': 2}, 'has': {'a': 2}, 'a': {'little': 2, 'lot': 1}, 'little': {'car': 1, 'star': 1}, 'car': {'*E*': 1}, 'star': {'*E*': 1}, 'say': {'what': 1}, 'what': {'a': 1}, 'lot': {'of': 1}, 'of': {'fish': 1}, 'there': {'are': 1}, 'are': {'*E*': 1, 'red': 1, 'blue': 1, 'old': 1, 'new': 1}, 'yes': {'some': 1}, 'some': {'are': 4}, 'and': {'some': 2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And print a more complex sentence\n",
    "print (generate_random_text(markov_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
