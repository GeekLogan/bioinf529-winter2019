{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class : Graphical Models - Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before Class\n",
    "In class today we will be implementing a Markov chain to process sentences\n",
    "Prior to class, please do the following:\n",
    "1. Review slides on Markov chains in detail\n",
    "* Explore using the python dict() structure and how a dict() can contain nested dict() structures\n",
    "* Again, review numpy.random.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "\n",
    "1. Conceptually understand Markov Chains\n",
    "* Implement a Markov Chain\n",
    "* Generate data using Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the lectures that Markov Chains represent a series of events following the Markov Property: future states are memory-less in that they depend only on the current state. This can be expanded to the idea of variable order Markov models where there is a variable-length memory (eg. 1st order Markov Model). Markov models consist of fully observable states. A common example of this is in predicting the weather: We can clearly see the current weather and would like to predict tomorrow's weather. As shown in the slides, this is also applicable to biology with one case being CpG islands. \n",
    "\n",
    "Our goal today will be to implement a Markov model built from words. For our example text, we will use the classic example of Dr. Seuss because of the repetitive nature of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Markov model\n",
    "\n",
    "For our initial implementation of the Markov Model, we will use the simple example of Dr. Seuss: \"One fish two fish red fish blue fish.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_markov_model(markov_model, new_text):\n",
    "    '''\n",
    "    Function to build or add to a 1st order Markov model given a string of text\n",
    "    We will store the markov model as a dictionary of dictionaries\n",
    "    The key in the outer dictionary represents the current state\n",
    "    and the inner dictionary represents the next state with their contents containing\n",
    "    the transition probabilities.\n",
    "    Note: This would be easier to read if we were to build a class representation\n",
    "           of the model rather than a dictionary of dictionaries, but for simplicitiy\n",
    "           our implementation will just use this structure.\n",
    "    \n",
    "    Args: \n",
    "        markov_model (dict of dicts): a dictionary of word:(next_word:frequency pairs)\n",
    "        new_text (str): a string to build or add to the moarkov_model\n",
    "\n",
    "    Returns:\n",
    "        markov_model (dict of dicts): an updated markov_model\n",
    "        \n",
    "    Pseudocode:\n",
    "        Add artificial states for start and end\n",
    "        For each word in text:\n",
    "            Increment markov_model[word][next_word]\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Split up our sentence by spaces\n",
    "    words = new_text.split()\n",
    "    \n",
    "    # Add our artifical start and end states to the sentence\n",
    "    words.insert(0, \"*S*\")\n",
    "    words.append(\"*E*\")\n",
    "    \n",
    "    # Iterate over each word in the input\n",
    "    for i in range(0, len(words)-1):\n",
    "        \n",
    "        # Here we do a lot of checking to properly initialize the dictionaries\n",
    "        # But the main goal is to increment a counter if we have seen word[i+1]\n",
    "        # after word[i]\n",
    "        if words[i] in markov_model:                     # If we have already seen this word\n",
    "            if words[i+1] in markov_model[words[i]]:     # and if we have already seen the next word\n",
    "                markov_model[words[i]][words[i+1]] += 1  # increment the word counter\n",
    "            else:\n",
    "                markov_model[words[i]][words[i+1]] = 1   # If we haven't seen the next word, create it\n",
    "        else:\n",
    "            markov_model[words[i]] = {}                  # If we haven't see the word then create it\n",
    "            markov_model[words[i]][words[i+1]] = 1\n",
    "    \n",
    "    return markov_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'*S*': {'one': 1}, 'one': {'fish': 1}, 'fish': {'two': 1, 'red': 1, 'blue': 1, '*E*': 1}, 'two': {'fish': 1}, 'red': {'fish': 1}, 'blue': {'fish': 1}}\n"
     ]
    }
   ],
   "source": [
    "markov_model = dict()\n",
    "text = \"one fish two fish red fish blue fish\"\n",
    "markov_model = build_markov_model(markov_model, text)\n",
    "print (markov_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "{'*S*': {'one': 1}, 'one': {'fish': 1}, 'fish': {'two': 1, 'red': 1, 'blue': 1, '*E*': 1}, 'two': {'fish': 1}, 'red': {'fish': 1}, 'blue': {'fish': 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text from Markov Model\n",
    "\n",
    "Markov models are \"generative models\". That is, the probability states in the model can be used to generate output following the conditional probabilities in the model.\n",
    "\n",
    "We will now generate a sequence of text from the Markov model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(current_word, markov_model):\n",
    "    '''\n",
    "    Function to randomly move a valid next state given a markov model\n",
    "    and a current state (word)\n",
    "    \n",
    "    Args: \n",
    "        current_word (str): a word that exists in our model\n",
    "        markov_model (dict of dicts): a dictionary of word:(next_word:frequency pairs)\n",
    "\n",
    "    Returns:\n",
    "        next_word (str): a randomly selected next word based on transition probabilies\n",
    "        \n",
    "    Pseudocode:\n",
    "        Calculate transition probilities for all next states from a given state (counts/sum)\n",
    "        Randomly draw from these to generate the next state\n",
    "        \n",
    "    '''\n",
    "    # Get all of our possible next states\n",
    "    next_words = list(markov_model[current_word].keys())\n",
    "    \n",
    "    # Calculate the probabilities to move to those based on word counts\n",
    "    next_words_frequencies = list(markov_model[current_word].values())\n",
    "    next_words_probabilities = [x / sum(next_words_frequencies) for x in next_words_frequencies]\n",
    "\n",
    "    # Randomly move to the next state\n",
    "    next_state = np.random.choice( next_words, 1, p=next_words_probabilities)\n",
    "\n",
    "    # Return next state\n",
    "    return next_state[0]\n",
    "\n",
    "    \n",
    "def generate_random_text(markov_model):\n",
    "    '''\n",
    "    Function to generate text given a markov model\n",
    "    \n",
    "    Args: \n",
    "        markov_model (dict of dicts): a dictionary of word:(next_word:frequency pairs)\n",
    "\n",
    "    Returns:\n",
    "        sentence (str): a randomly generated sequence given the model\n",
    "        \n",
    "    Pseudocode:\n",
    "        Initialize sentence at start state\n",
    "        Until End State:\n",
    "            append get_next_word(current_word, markov_model)\n",
    "        Return sentence\n",
    "        \n",
    "    '''\n",
    "    # We must start at the initial state of the model\n",
    "    current_word = \"*S*\"\n",
    "    \n",
    "    # Keeping track of the sentence as a list (ignoring the start state)\n",
    "    sentence = []\n",
    "\n",
    "    # Until the model generates an end state, keep adding random words\n",
    "    while current_word != \"*E*\":\n",
    "        current_word = get_next_word(current_word, markov_model)\n",
    "        \n",
    "        # Don't append the end state to our output\n",
    "        if current_word != \"*E*\":\n",
    "            sentence.append(current_word)\n",
    "    \n",
    "    # Return the words with spaces between them\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one fish two fish red fish\n"
     ]
    }
   ],
   "source": [
    "# Print a random sentence from our markov chain:\n",
    "print (generate_random_text(markov_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'*S*': {'one': 1, 'black': 1, 'this': 2, 'say': 1, 'yes': 1, 'some': 1}, 'one': {'fish': 1, 'has': 2}, 'fish': {'two': 1, 'red': 1, 'blue': 2, '*E*': 2, 'old': 1, 'new': 1, 'there': 1}, 'two': {'fish': 1}, 'red': {'fish': 1, 'and': 1}, 'blue': {'fish': 2, '*E*': 1}, 'black': {'fish': 1}, 'old': {'fish': 1, 'and': 1}, 'new': {'fish': 1, '*E*': 1}, 'this': {'one': 2}, 'has': {'a': 2}, 'a': {'little': 2, 'lot': 1}, 'little': {'car': 1, 'star': 1}, 'car': {'*E*': 1}, 'star': {'*E*': 1}, 'say': {'what': 1}, 'what': {'a': 1}, 'lot': {'of': 1}, 'of': {'fish': 1}, 'there': {'are': 1}, 'are': {'*E*': 1, 'red': 1, 'blue': 1, 'old': 1, 'new': 1}, 'yes': {'some': 1}, 'some': {'are': 4}, 'and': {'some': 2}}\n"
     ]
    }
   ],
   "source": [
    "# Now just add some more training data to the markov model\n",
    "markov_model = build_markov_model(markov_model, \"black fish blue fish old fish new fish\")\n",
    "markov_model = build_markov_model(markov_model, \"this one has a little car\")\n",
    "markov_model = build_markov_model(markov_model, \"this one has a little star\")\n",
    "markov_model = build_markov_model(markov_model, \"say what a lot of fish there are\")\n",
    "markov_model = build_markov_model(markov_model, \"yes some are red and some are blue\")\n",
    "markov_model = build_markov_model(markov_model, \"some are old and some are new\")\n",
    "\n",
    "print(markov_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "{'*S*': {'one': 1, 'black': 1, 'this': 2, 'say': 1, 'yes': 1, 'some': 1}, 'one': {'fish': 1, 'has': 2}, 'fish': {'two': 1, 'red': 1, 'blue': 2, '*E*': 2, 'old': 1, 'new': 1, 'there': 1}, 'two': {'fish': 1}, 'red': {'fish': 1, 'and': 1}, 'blue': {'fish': 2, '*E*': 1}, 'black': {'fish': 1}, 'old': {'fish': 1, 'and': 1}, 'new': {'fish': 1, '*E*': 1}, 'this': {'one': 2}, 'has': {'a': 2}, 'a': {'little': 2, 'lot': 1}, 'little': {'car': 1, 'star': 1}, 'car': {'*E*': 1}, 'star': {'*E*': 1}, 'say': {'what': 1}, 'what': {'a': 1}, 'lot': {'of': 1}, 'of': {'fish': 1}, 'there': {'are': 1}, 'are': {'*E*': 1, 'red': 1, 'blue': 1, 'old': 1, 'new': 1}, 'yes': {'some': 1}, 'some': {'are': 4}, 'and': {'some': 2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some are red and some are old fish blue fish new fish blue\n"
     ]
    }
   ],
   "source": [
    "# And print a more complex sentence\n",
    "print (generate_random_text(markov_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
